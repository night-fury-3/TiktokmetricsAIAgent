# üß™ Comprehensive Testing Guide - TikTok Metrics AI Agent

## Overview
This guide provides detailed testing procedures for both Task 1 (KPI Algorithm Optimization) and Task 2 (Revenue Optimization AI Pipeline).

## üéØ Task 1: KPI Algorithm Optimization Testing

### Test Objective
Validate the multi-tier weighted algorithm that prioritizes e-commerce revenue drivers over equal weighting.

### Test Scenarios

#### Scenario 1.1: Equal Weighting vs Optimized Algorithm Comparison
**Purpose**: Demonstrate the 8.6% improvement over equal weighting

**Test Steps**:
1. Use demo data with mixed performance levels
2. Compare new algorithm vs old equal weighting
3. Verify revenue focus improvement

**Expected Results**:
- New algorithm should show higher overall scores
- Revenue-focused KPIs should have higher impact
- Clear percentage improvement over baseline

#### Scenario 1.2: Tier Weight Validation
**Purpose**: Verify correct weight distribution across tiers

**Test Steps**:
1. Check Tier 1 (Revenue Drivers): 55% total weight
2. Check Tier 2 (Revenue Enablers): 32% total weight  
3. Check Tier 3 (General Health): 13% total weight

**Expected Results**:
- Sales Performance: 30% weight
- Shop Conversion: 15% weight
- TikTok Shop: 10% weight
- All weights sum to 100%

#### Scenario 1.3: Revenue Focus Validation
**Purpose**: Ensure revenue drivers have maximum impact

**Test Steps**:
1. Create high revenue, low engagement scenario
2. Create low revenue, high engagement scenario
3. Compare overall scores

**Expected Results**:
- High revenue scenario should score higher
- Revenue focus should override engagement metrics
- Clear business alignment with e-commerce goals

## üéØ Task 2: Revenue Optimization AI Pipeline Testing

### Test Objective
Validate the AI recommendation system that diagnoses bottlenecks and provides actionable insights.

### Test Scenarios

#### Scenario 2.1: Bottleneck Identification
**Purpose**: Test automated diagnosis of performance issues

**Test Steps**:
1. Input creator with low conversion rates
2. Input creator with high cart abandonment
3. Input creator with poor video quality
4. Verify correct bottleneck identification

**Expected Results**:
- Low conversion ‚Üí Sales Performance bottleneck
- High abandonment ‚Üí Shop Conversion bottleneck
- Poor quality ‚Üí Content Strategy bottleneck

#### Scenario 2.2: Recommendation Generation
**Purpose**: Test actionable recommendation creation

**Test Steps**:
1. Analyze creator with identified bottlenecks
2. Verify recommendation priority scoring
3. Check expected improvement calculations
4. Validate A/B test configurations

**Expected Results**:
- Priority-based ranking of recommendations
- Specific, actionable improvement steps
- Expected impact percentages
- Complete A/B test setups

#### Scenario 2.3: Revenue Impact Analysis
**Purpose**: Validate revenue-focused optimization

**Test Steps**:
1. Test with revenue-focused KPIs
2. Verify improvement potential calculations
3. Check ROI-focused recommendations

**Expected Results**:
- Revenue KPIs prioritized in recommendations
- Clear improvement potential metrics
- ROI-driven action prioritization

## üß™ Detailed Testing Procedures

### Prerequisites
1. Application running on http://localhost:8000
2. All dependencies installed
3. Demo data available

### Test Data Sets

#### High Revenue Creator
```json
{
  "creator_id": "high_revenue_creator",
  "conversion_rate": 0.12,
  "total_revenue": 25000,
  "avg_order_value": 85,
  "funnel_completion_rate": 0.8,
  "cart_abandonment_rate": 0.2,
  "video_quality": 0.9,
  "engagement_score": 0.7
}
```

#### Low Revenue Creator
```json
{
  "creator_id": "low_revenue_creator", 
  "conversion_rate": 0.02,
  "total_revenue": 1000,
  "avg_order_value": 25,
  "funnel_completion_rate": 0.2,
  "cart_abandonment_rate": 0.8,
  "video_quality": 0.3,
  "engagement_score": 0.9
}
```

#### Mixed Performance Creator
```json
{
  "creator_id": "mixed_performance_creator",
  "conversion_rate": 0.05,
  "total_revenue": 5000,
  "avg_order_value": 45,
  "funnel_completion_rate": 0.3,
  "cart_abandonment_rate": 0.7,
  "video_quality": 0.3,
  "engagement_score": 0.6
}
```

## üîç Testing Methods

### Method 1: API Testing
Use curl commands to test individual endpoints

### Method 2: Frontend Testing
Use the interactive dashboard for visual testing

### Method 3: Automated Testing
Use Python scripts for comprehensive validation

### Method 4: Load Testing
Test with multiple concurrent requests

## üìä Success Criteria

### Task 1 Success Criteria
- [ ] Algorithm shows 8.6% improvement over equal weighting
- [ ] Revenue drivers have 55% total weight
- [ ] Revenue-focused creators score higher than engagement-focused
- [ ] Clear business alignment with e-commerce goals

### Task 2 Success Criteria
- [ ] Correct bottleneck identification for different scenarios
- [ ] Actionable recommendations with priority scoring
- [ ] Expected improvement calculations are realistic
- [ ] A/B test configurations are complete and valid
- [ ] Revenue-focused optimization is evident

## üö® Common Issues & Solutions

### Issue 1: Import Errors
**Solution**: Ensure PYTHONPATH is set correctly

### Issue 2: Port Already in Use
**Solution**: Stop existing processes or use different port

### Issue 3: API Timeout
**Solution**: Check application logs and restart if needed

### Issue 4: Frontend Not Loading
**Solution**: Verify static files are being served correctly

## üìà Performance Benchmarks

### Response Time Targets
- Health check: < 100ms
- Analysis endpoint: < 500ms
- Demo data: < 200ms
- Frontend load: < 2s

### Accuracy Targets
- Bottleneck identification: > 90%
- Recommendation relevance: > 85%
- Algorithm improvement: > 8%

## üîÑ Continuous Testing

### Daily Tests
- Health check validation
- Basic functionality testing
- Performance monitoring

### Weekly Tests
- Full scenario testing
- Load testing
- Accuracy validation

### Monthly Tests
- Algorithm performance review
- Recommendation quality assessment
- Business impact analysis
